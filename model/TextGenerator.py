import numpy as np
import nltk
import logging

from keras_preprocessing.text import text_to_word_sequence

logging.basicConfig(level=logging.DEBUG)


class TextGenerator:
    # RNS Not sure if needed
    SENT_START_TOKEN = "SENTENCE_START"
    SENT_END_TOKEN = "SENTENCE_END"
    UNKNOWN_TOKEN = "UNKNOWN_TOKEN"
    PAD_TOKEN = "PADDING"

    def __init__(self, model, index_to_word, word_to_index, sent_max_len=30):
        self.model = model
        self.index_to_word = index_to_word
        self.word_to_index = word_to_index
        self.vocabulary_size = len(word_to_index)
        self.unknown_token_idx = self.word_to_index[self.UNKNOWN_TOKEN]
        self.pad_token_idx = self.word_to_index[self.PAD_TOKEN]
        self.sent_max_len = sent_max_len
        self.start_token_idx = self.word_to_index.get(self.SENT_START_TOKEN, None)
        self.end_token_idx = self.word_to_index.get(self.SENT_END_TOKEN, None)
        self.model_type = 'delimited'

    def get_sentence(self, sent_min_len, seed=None, seed_max_len=10):
        """
        Returns a sentence generated by the model.
        Method will loop on generated sentences until requirements are met.
        :param sent_min_len: minimum length acceptable for the sentence
        :param seed: seed text to use for the generation task
        :param seed_max_len: max length used for the seed (operated pre-truncation)
        :return: the generated string
        """
        if seed == '':
            seed = None

        start_sentence = self._generate_start_sentence(seed_max_len, seed)

        sent = None
        while not sent:
            sent = self._generate_sentence(sent_min_len, start_sentence)
        return sent

    def _generate_start_sentence(self, max_len, seed=None):
        """
        Generate sentence based on seed text.
        Sentence should then be feed to the model for the actual text generation task.
        """
        # if we have some seed text, start with that
        if seed:
            idx_sentence = self.transform_sentence(seed, max_len)
        else:
            if self.start_token_idx:
                start_token_idx = self.start_token_idx
                # otherwise use random token index
            else:
                start_token_idx = np.random.randint(self.vocabulary_size)
            idx_sentence = np.array([start_token_idx])

        return idx_sentence

    def _generate_sentence(self, min_len, seed_sentence):
        """
        Main procedure for sentence generation.
        :param min_len: minimum length acceptable for the generated sentence
        :param seed_sentence: seed sentence on which to build newly generated text (can be either one-hot or word-index encoded)
        :return:
        """

        res_sentence = []

        while True:
            # Index from which we will sample is the one corresponding to index of last
            # word in the fed sentence (RNN next predicted word)
            current_idx = max(0, len(seed_sentence) - 1)

            # Make predictions and sample index based on returned probabilities
            words_probs = self._model_predict(seed_sentence, idx=current_idx)
            sampled_index = TextGenerator.sample_from_prediction(words_probs)

            # TODO could try some more sampling before throwing away already done work?
            # Skip if sentence is getting too long or we got an unwanted token
            if len(res_sentence) >= self.sent_max_len \
                    or sampled_index == self.unknown_token_idx \
                    or sampled_index == self.pad_token_idx:
                return None

            # Append result to sentences
            res_sentence.append(sampled_index)
            # append also to seed sentence (just index if with embedding, one-hot encoded if without
            seed_sentence = np.append(seed_sentence, [sampled_index], axis=0)

            # Return if we get an end token and sentence is long enough
            if len(res_sentence) > min_len and (not self.end_token_idx or sampled_index == self.end_token_idx):
                return res_sentence

    def _model_predict(self, sentence, idx=None):
        """
        Model prediction based on give sentence
        :param sentence: sentence to use (one-hot encoded)
        :param idx: if specified, return only probabilities for such index
        """
        # Give required shape (sample=1, sent_len, voc_size)
        x = np.expand_dims(sentence, 0)  # fit to the RNN model
        predictions = self.model.predict(x)
        if not idx is None:
            return predictions[0][idx]
        else:
            return predictions

    @staticmethod
    def sample_from_prediction(predictions):
        """
        Sample an index from given prediction (a probability distribution)
        :param predictions:
        :return:
        """
        p = np.log(np.asarray(predictions).astype('float64'))
        p = np.exp(p) / np.sum(np.exp(p))
        try:
            idx = np.argmax(np.random.multinomial(1, p, 1))
        except ValueError as e:
            logging.debug(e)
            return np.random.choice(len(predictions), 1, p=predictions)[0]
        return idx

    def transform_sentence(self, sentence, max_len):
        """
        Takes a sentence as string and transform it as required by the model
        (tokenize, words to index)
        """
        # Tokenize
        words = nltk.word_tokenize(sentence.lower())  # consider adding lower

        idx_sentence = [self.word_to_index.get(w, self.unknown_token_idx) for w in words[-max_len:]]
        return idx_sentence

    def indices_to_words(self, index_sent):
        """
        Converts from a list of word indices back to a sentence of words
        :param index_sent: sentence of indices
        :return:
        """
        # Trim off end token padding
        if self.model_type == 'delimited':
            index_sent = index_sent[:-1]
        # convert sentence from word_indexes to string
        words = [self.index_to_word[word_idx].strip() for word_idx in index_sent]
        return " ".join(words).strip()
